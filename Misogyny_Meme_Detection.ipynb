{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5djvz6VQZgbQ",
        "outputId": "909854fc-6c7b-439d-df90-f2337a8b2ad4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import models, transforms\n",
        "from transformers import BertTokenizer, BertModel\n",
        "from torchvision.models import ResNet50_Weights\n",
        "\n",
        "# --- Hyperparameters ---\n",
        "BATCH_SIZE = 8  # Reduced for faster training\n",
        "EPOCHS = 5\n",
        "LR = 1e-4\n"
      ],
      "metadata": {
        "id": "5kvikg2eaacg"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Path**"
      ],
      "metadata": {
        "id": "mHS6SWNy-paa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "TRAIN_CSV = '/content/drive/MyDrive/Project 3/train.csv'\n",
        "DEV_CSV = '/content/drive/MyDrive/Project 3/dev.csv'\n",
        "TRAIN_IMG_DIR = '/content/drive/MyDrive/Project 3/train'\n",
        "DEV_IMG_DIR = '/content/drive/MyDrive/Project 3/dev'\n",
        "TEST_IMG_DIR = '/content/drive/MyDrive/Project 3/test'\n"
      ],
      "metadata": {
        "id": "DeUvOBI7avvi"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv(TRAIN_CSV)\n",
        "print(df.head())\n",
        "print(df.columns)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VfX9PaoWf2Xi",
        "outputId": "f3dd7841-872a-4ef6-b7a8-b8cc7dbd3cac"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  image_name        labels                  transcriptions\n",
            "0   1134.jpg      Misogyny  å¦‚æœç»“å©šæ˜¯å¥½äº‹çš„è¯ æŒ‰ç…§æˆ‘å›½çš„å›½æƒ… åº”è¯¥æ‰˜å…³ç³»èµ°åé—¨æ‰èƒ½ç»“å©š\n",
            "1    901.jpg  Not-Misogyny                        ç‹ ç‹ æœŸå¾… å¥½äº†å˜›\n",
            "2    683.jpg      Misogyny         ä¸ºä»€ä¹ˆä¸ç”Ÿå­©å­ï¼Ÿ è®©ç”·çš„ç”Ÿå‘— ä»–ä»¬ä¸æ˜¯å…ˆç”Ÿå˜›ï¼Ÿ\n",
            "3    768.jpg  Not-Misogyny        æä¸æ‡‚å‘¢ ä½ çŸ¥é“æ»´ æˆ‘ä¸è¿‡æ˜¯ æ¥è‡ªå¤§å±±æ·±å¤„çš„å—å–½\n",
            "4    178.jpg  Not-Misogyny                 ä¹°å®ŒåŒæ¬¾ä¹°åŒæ¬¾ å®¶é‡Œå¯ä»¥å¼€å±•è§ˆ\n",
            "Index(['image_name', 'labels', 'transcriptions'], dtype='object')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv(DEV_CSV)\n",
        "print(df.head())\n",
        "print(df.columns)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3acSuI3VgijY",
        "outputId": "5490d0d4-080b-48da-aeaf-0507e7ae3631"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  image_name        labels                                     transcriptions\n",
            "0    423.jpg  Not-Misogyny                                   æƒ³æˆ‘çš„ç”Ÿæ´»...æ€»æ˜¯å·®ä¸€ç‚¹å°±é¡ºå‘\n",
            "1    204.jpg      Misogyny                 å­©å­ä¸å¬è¯æ˜¯ä½ ä¸å¯¹ å­©å­å­¦ä¹ æˆç»©ä¸å¥½ è¿˜æ˜¯ä½ ä¸å¯¹ EN EN å¬æˆ‘è¯´\n",
            "2    571.jpg      Misogyny                       åŒäº‹ï¼š ä½ å•¥æ—¶å€™ç”Ÿå­©å­å•Š æˆ‘ï¼š ä½ æ˜¯ä¸æ˜¯ç€æ€¥æŠ•èƒå«æˆ‘å¦ˆå•Š\n",
            "3    323.jpg  Not-Misogyny                                              å»ä½ çš„è°ƒä¼‘\n",
            "4   1403.jpg  Not-Misogyny  å›½åº†7å¤©+ä¸­ç§‹3å¤© è°ƒä¼‘å®Œç­‰äºæ€»å…±æ”¾4å¤© ä¸Šæ¬¡é‡åˆ°è¿™ç§7+3=4çš„é¢˜ç›® è¿˜æ˜¯æ ‘ä¸Šéª‘ä¸ªçŒ´åœ°ä¸Šä¸‰...\n",
            "Index(['image_name', 'labels', 'transcriptions'], dtype='object')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Dataset**"
      ],
      "metadata": {
        "id": "1LU0Oyxy-xpc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MemeDataset(Dataset):\n",
        "    def __init__(self, csv_file, image_dir, tokenizer, transform, is_test=False):\n",
        "        self.image_dir = image_dir\n",
        "        self.tokenizer = tokenizer\n",
        "        self.transform = transform\n",
        "        self.is_test = is_test\n",
        "\n",
        "        if not is_test:\n",
        "            self.data = pd.read_csv(csv_file)\n",
        "        else:\n",
        "            self.image_names = sorted([f for f in os.listdir(image_dir) if f.lower().endswith(('.png', '.jpg', '.jpeg'))])\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_names) if self.is_test else len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        if self.is_test:\n",
        "            image_name = self.image_names[idx]\n",
        "            image_path = os.path.join(self.image_dir, image_name)\n",
        "            image = self.transform(Image.open(image_path).convert('RGB'))\n",
        "            dummy_text = \"\"\n",
        "            encoded_text = self.tokenizer(dummy_text, padding='max_length', truncation=True, max_length=64, return_tensors='pt')\n",
        "            return image, encoded_text['input_ids'].squeeze(0), encoded_text['attention_mask'].squeeze(0), image_name\n",
        "        else:\n",
        "            image_name = self.data.iloc[idx]['image_name']\n",
        "            image_path = os.path.join(self.image_dir, image_name)\n",
        "            image = self.transform(Image.open(image_path).convert('RGB'))\n",
        "            transcription = self.data.iloc[idx]['transcriptions']\n",
        "            encoded_text = self.tokenizer(transcription, padding='max_length', truncation=True, max_length=64, return_tensors='pt')\n",
        "            label_str = self.data.iloc[idx]['labels']\n",
        "            label = 1 if label_str.lower() == 'misogyny' else 0\n",
        "            return image, encoded_text['input_ids'].squeeze(0), encoded_text['attention_mask'].squeeze(0), label, image_name"
      ],
      "metadata": {
        "id": "uzYtG4dJgnb1"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "sample_dataset = MemeDataset(TRAIN_CSV, TRAIN_IMG_DIR, tokenizer, transform)\n",
        "sample_item = sample_dataset[0]\n",
        "print(\"âœ… Sample image tensor shape:\", sample_item[0].shape)\n",
        "print(\"âœ… Sample text input ids shape:\", sample_item[1].shape)\n",
        "print(\"âœ… Sample label:\", sample_item[3])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IVyt5yVTg4lS",
        "outputId": "49ab50ae-8043-4446-f806-c9c776afcde5"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Sample image tensor shape: torch.Size([3, 224, 224])\n",
            "âœ… Sample text input ids shape: torch.Size([64])\n",
            "âœ… Sample label: 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Model**"
      ],
      "metadata": {
        "id": "Wdx9cN0X_lqC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MultimodalClassifier(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(MultimodalClassifier, self).__init__()\n",
        "        self.image_model = models.resnet50(weights=ResNet50_Weights.DEFAULT)\n",
        "        self.image_model.fc = nn.Identity()\n",
        "        for param in self.image_model.parameters():  # Freeze ResNet\n",
        "            param.requires_grad = False\n",
        "\n",
        "        self.text_model = BertModel.from_pretrained('bert-base-uncased')\n",
        "        for param in self.text_model.parameters():  # Freeze BERT\n",
        "            param.requires_grad = False\n",
        "\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(2048 + 768, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.2),\n",
        "            nn.Linear(512, 2)\n",
        "        )\n",
        "\n",
        "    def forward(self, img, input_ids, attention_mask):\n",
        "        img_feat = self.image_model(img)\n",
        "        text_feat = self.text_model(input_ids=input_ids, attention_mask=attention_mask).pooler_output.detach()\n",
        "        combined = torch.cat((img_feat, text_feat), dim=1)\n",
        "        return self.classifier(combined)"
      ],
      "metadata": {
        "id": "0X2k0jYDg7Bt"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = MultimodalClassifier()\n",
        "img, ids, mask, label, _ = sample_dataset[0]\n",
        "with torch.no_grad():\n",
        "    out = model(img.unsqueeze(0), ids.unsqueeze(0), mask.unsqueeze(0))\n",
        "print(\"âœ… Model output shape:\", out.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9b0ZQUSIhDe7",
        "outputId": "b3a6f8c6-d6be-45f0-f73c-89618e8e0f63"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Model output shape: torch.Size([1, 2])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Initialize**"
      ],
      "metadata": {
        "id": "0_z6jXVg_sA7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "model = MultimodalClassifier().to(device)\n",
        "optimizer = torch.optim.Adam(model.classifier.parameters(), lr=LR)  # Only train classifier\n",
        "criterion = nn.CrossEntropyLoss()"
      ],
      "metadata": {
        "id": "2bkt1_MkhH4y"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Dataloader**"
      ],
      "metadata": {
        "id": "wszcM-Jm_hFK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = MemeDataset(TRAIN_CSV, TRAIN_IMG_DIR, tokenizer, transform)\n",
        "dev_dataset = MemeDataset(DEV_CSV, DEV_IMG_DIR, tokenizer, transform)\n",
        "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "dev_loader = DataLoader(dev_dataset, batch_size=BATCH_SIZE)"
      ],
      "metadata": {
        "id": "8xHQrkrChU0F"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample_batch = next(iter(train_loader))\n",
        "print(\"âœ… Batch image shape:\", sample_batch[0].shape)\n",
        "print(\"âœ… Batch input_ids shape:\", sample_batch[1].shape)\n",
        "print(\"âœ… Batch labels:\", sample_batch[3])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_u2A62Ljhcs1",
        "outputId": "a516139c-8da8-43f0-d651-ed112acf2aa2"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Batch image shape: torch.Size([8, 3, 224, 224])\n",
            "âœ… Batch input_ids shape: torch.Size([8, 64])\n",
            "âœ… Batch labels: tensor([0, 0, 0, 0, 0, 0, 1, 0])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Training**"
      ],
      "metadata": {
        "id": "--OS0yQy_eeM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(EPOCHS):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    for img, ids, mask, labels, _ in tqdm(train_loader):\n",
        "        img, ids, mask, labels = img.to(device), ids.to(device), mask.to(device), labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(img, ids, mask)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "    print(f\"Epoch {epoch+1}/{EPOCHS} - Loss: {total_loss/len(train_loader):.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TZ-K2fwJheWh",
        "outputId": "a2343b62-b088-40ca-d7ff-10b35ce2a0db"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 149/149 [15:55<00:00,  6.41s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5 - Loss: 0.5570\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 149/149 [09:38<00:00,  3.88s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2/5 - Loss: 0.4731\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 149/149 [09:35<00:00,  3.86s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3/5 - Loss: 0.4247\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 149/149 [09:36<00:00,  3.87s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4/5 - Loss: 0.3853\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 149/149 [09:37<00:00,  3.88s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5/5 - Loss: 0.3853\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Inference**"
      ],
      "metadata": {
        "id": "e4-dwuZ4_aWJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_dataset = MemeDataset(None, TEST_IMG_DIR, tokenizer, transform, is_test=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE)\n",
        "\n",
        "model.eval()\n",
        "predictions = []\n",
        "with torch.no_grad():\n",
        "    for img, ids, mask, image_names in tqdm(test_loader):\n",
        "        img, ids, mask = img.to(device), ids.to(device), mask.to(device)\n",
        "        outputs = model(img, ids, mask)\n",
        "        preds = torch.argmax(outputs, dim=1).cpu().tolist()\n",
        "        predictions.extend(zip(image_names, preds))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w5FN8NOShoJI",
        "outputId": "f4755402-adca-4862-83c7-ed99558b2476"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 43/43 [02:57<00:00,  4.12s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "submission = pd.DataFrame(predictions, columns=['image_name', 'labels'])\n",
        "submission['labels'] = submission['labels'].map({1: 'Misogyny', 0: 'Not-Misogyny'})\n",
        "submission.to_csv(\"submission.csv\", index=False)\n",
        "print(\"âœ… Submission file saved as 'SSNCSE_run1.csv'\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o11mnFXrhr8q",
        "outputId": "9d7d94b8-a364-467f-aeff-f1eded15681b"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Submission file saved as 'SSNCSE_run1.csv'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Classification report for Development data**"
      ],
      "metadata": {
        "id": "xeRMMyGf_LwE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# --- Evaluation on Dev Set ---\n",
        "model.eval()\n",
        "all_preds = []\n",
        "all_labels = []\n",
        "with torch.no_grad():\n",
        "    for img, ids, mask, labels, _ in tqdm(dev_loader):\n",
        "        img, ids, mask = img.to(device), ids.to(device), mask.to(device)\n",
        "        outputs = model(img, ids, mask)\n",
        "        preds = torch.argmax(outputs, dim=1).cpu().tolist()\n",
        "        all_preds.extend(preds)\n",
        "        all_labels.extend(labels.tolist())\n",
        "\n",
        "# --- Classification Report ---\n",
        "report = classification_report(all_labels, all_preds, target_names=['Not-Misogyny', 'Misogyny'])\n",
        "print(\"ğŸ“Š Classification Report on Dev Set:\")\n",
        "print(report)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n7UgF9TQiLBy",
        "outputId": "2089efd8-5448-412c-ac04-a6b2709aafa1"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 22/22 [02:34<00:00,  7.01s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸ“Š Classification Report on Dev Set:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "Not-Misogyny       0.86      0.92      0.89       123\n",
            "    Misogyny       0.74      0.62      0.67        47\n",
            "\n",
            "    accuracy                           0.84       170\n",
            "   macro avg       0.80      0.77      0.78       170\n",
            "weighted avg       0.83      0.84      0.83       170\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    }
  ]
}